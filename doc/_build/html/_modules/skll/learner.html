<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>skll.learner &mdash; SciKit-Learn Lab 0.9 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.9',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="SciKit-Learn Lab 0.9 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">SciKit-Learn Lab 0.9 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for skll.learner</h1><div class="highlight"><pre>
<span class="c">#!/usr/bin/env python</span>

<span class="c"># Copyright (C) 2012-2013 Educational Testing Service</span>

<span class="c"># This file is part of SciKit-Learn Lab.</span>

<span class="c"># SciKit-Learn Lab is free software: you can redistribute it and/or modify</span>
<span class="c"># it under the terms of the GNU General Public License as published by</span>
<span class="c"># the Free Software Foundation, either version 3 of the License, or</span>
<span class="c"># (at your option) any later version.</span>

<span class="c"># SciKit-Learn Lab is distributed in the hope that it will be useful,</span>
<span class="c"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c"># GNU General Public License for more details.</span>

<span class="c"># You should have received a copy of the GNU General Public License</span>
<span class="c"># along with SciKit-Learn Lab.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Module with many functions to use for easily creating a scikit-learn learner</span>

<span class="sd">:author: Michael Heilman (mheilman@ets.org)</span>
<span class="sd">:author: Nitin Madnani (nmadnani@ets.org)</span>
<span class="sd">:author: Dan Blanchard (dblanchard@ets.org)</span>
<span class="sd">:organization: ETS</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">islice</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="kn">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="kn">as</span> <span class="nn">sk_metrics</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">UnicodeDammit</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">clone</span><span class="p">,</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">LeaveOneLabelOut</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span><span class="p">,</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">DictVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">IterGrid</span><span class="p">,</span> <span class="n">_has_one_grid_point</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span><span class="p">,</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn.svm.base</span> <span class="kn">import</span> <span class="n">BaseLibLinear</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">safe_mask</span><span class="p">,</span> <span class="n">check_arrays</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="n">_num_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">six</span> <span class="kn">import</span> <span class="n">iteritems</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">zip</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">xrange</span> <span class="k">as</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="n">cPickle</span> <span class="k">as</span> <span class="n">pickle</span>
<span class="kn">from</span> <span class="nn">six</span> <span class="kn">import</span> <span class="n">string_types</span>

<span class="kn">from</span> <span class="nn">skll.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">quadratic_weighted_kappa</span><span class="p">,</span> <span class="n">unweighted_kappa</span><span class="p">,</span>
                          <span class="n">kendall_tau</span><span class="p">,</span> <span class="n">f1_score_micro</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                          <span class="n">_CORRELATION_METRICS</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">skll.fixed_standard_scaler</span> <span class="kn">import</span> <span class="n">FixedStandardScaler</span>

<span class="c"># Constants #</span>
<span class="n">_REQUIRES_DENSE</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">([</span><span class="s">&#39;naivebayes&#39;</span><span class="p">,</span> <span class="s">&#39;rforest&#39;</span><span class="p">,</span> <span class="s">&#39;gradient&#39;</span><span class="p">,</span> <span class="s">&#39;dtree&#39;</span><span class="p">,</span>
                             <span class="s">&#39;gb_regressor&#39;</span><span class="p">])</span>
<span class="n">_REGRESSION_MODELS</span> <span class="o">=</span> <span class="nb">frozenset</span><span class="p">([</span><span class="s">&#39;ridge&#39;</span><span class="p">,</span> <span class="s">&#39;rescaled_ridge&#39;</span><span class="p">,</span> <span class="s">&#39;svr_linear&#39;</span><span class="p">,</span>
                                <span class="s">&#39;rescaled_svr_linear&#39;</span><span class="p">,</span> <span class="s">&#39;gb_regressor&#39;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_predict_binary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Little helper function to allow us to use `GridSearchCV` with objective</span>
<span class="sd">    functions like Kendall&#39;s tau for binary classification problems (where the</span>
<span class="sd">    probability of the true class is used as the input to the objective</span>
<span class="sd">    function).</span>

<span class="sd">    This only works if we&#39;ve also taken the step of storing the old predict</span>
<span class="sd">    function for `self` as `predict_normal`. It&#39;s kind of a hack, but it saves</span>
<span class="sd">    us from having to override GridSearchCV to change one little line.</span>

<span class="sd">    :param self: A scikit-learn classifier instance</span>
<span class="sd">    :param X: A set of examples to predict values for.</span>
<span class="sd">    :type X: array</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_normal</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<div class="viewcode-block" id="SelectByMinCount"><a class="viewcode-back" href="../../skll.html#skll.learner.SelectByMinCount">[docs]</a><span class="k">class</span> <span class="nc">SelectByMinCount</span><span class="p">(</span><span class="n">SelectKBest</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Select features ocurring in more (and/or fewer than) than a specified</span>
<span class="sd">    number of examples in the training data (or a CV training fold).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_count</span> <span class="o">=</span> <span class="n">min_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scores_</span> <span class="o">=</span> <span class="bp">None</span>

<div class="viewcode-block" id="SelectByMinCount.fit"><a class="viewcode-back" href="../../skll.html#skll.learner.SelectByMinCount.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># initialize a list of counts of times each feature appears</span>
        <span class="n">col_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="c"># find() is scipy.sparse&#39;s equivalent of nonzero()</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># assume it&#39;s a numpy array (not a numpy matrix)</span>
            <span class="n">col_indices</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">col_indices</span><span class="p">:</span>
            <span class="n">col_counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scores_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">col_counts</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
</div>
    <span class="k">def</span> <span class="nf">_get_support_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Returns an indication of which features to keep.</span>
<span class="sd">        Adapted from SelectKBest.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scores_</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">mask</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scores_</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_count</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="n">mask</span>

</div>
<div class="viewcode-block" id="RescaledRegressionMixin"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRegressionMixin">[docs]</a><span class="k">class</span> <span class="nc">RescaledRegressionMixin</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Mixin to create regressors that store a min and a max for the training data</span>
<span class="sd">    and make sure that predictions fall within that range.  It also stores the</span>
<span class="sd">    means and SDs of the gold standard and the predictions on the training set</span>
<span class="sd">    to rescale the predictions (e.g., as in e-rater).</span>
<span class="sd">    &#39;&#39;&#39;</span>
<div class="viewcode-block" id="RescaledRegressionMixin.rescale_fit"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRegressionMixin.rescale_fit">[docs]</a>    <span class="k">def</span> <span class="nf">rescale_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Fit a model, then store the mean, SD, max and min of the training set</span>
<span class="sd">        and the mean and SD of the predictions on the training set.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c"># fit a regular regression model</span>
        <span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">constrain</span><span class="p">:</span>
            <span class="c"># also record the training data min and max</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">:</span>
            <span class="c"># also record the means and SDs for the training set</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">yhat_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">yhat_sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="RescaledRegressionMixin.rescale_predict"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRegressionMixin.rescale_predict">[docs]</a>    <span class="k">def</span> <span class="nf">rescale_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Make predictions with the super class, and then adjust them using the</span>
<span class="sd">        stored min, max, means, and standard deviations.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># get the unconstrained predictions</span>
        <span class="n">res</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">:</span>
            <span class="c"># convert the predictions to z-scores,</span>
            <span class="c"># then rescale to match the training set distribution</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">(((</span><span class="n">res</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat_mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat_sd</span><span class="p">)</span>
                   <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_sd</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">constrain</span><span class="p">:</span>
            <span class="c"># apply min and max constraints</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_min</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_max</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
                            <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">res</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">res</span>
</div>
<div class="viewcode-block" id="RescaledRegressionMixin.rescale_get_param_names"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRegressionMixin.rescale_get_param_names">[docs]</a>    <span class="k">def</span> <span class="nf">rescale_get_param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This is adapted from scikit-learns&#39;s BaseEstimator class.</span>
<span class="sd">        It gets the kwargs for the superclass&#39;s init method and adds the</span>
<span class="sd">        kwargs for the rescale_init method.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">,</span>
                           <span class="s">&#39;deprecated_original&#39;</span><span class="p">,</span>
                           <span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">)</span>

            <span class="n">args</span><span class="p">,</span> <span class="n">varargs</span><span class="p">,</span> <span class="n">__</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getargspec</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">varargs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s">&#39;scikit-learn estimators should always &#39;</span>
                                   <span class="s">&#39;specify their parameters in the signature&#39;</span>
                                   <span class="s">&#39; of their init (no varargs).&#39;</span><span class="p">)</span>
            <span class="c"># Remove &#39;self&#39;</span>
            <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">rescale_args</span><span class="p">,</span> <span class="n">__</span><span class="p">,</span> <span class="n">__</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getargspec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rescale_init</span><span class="p">)</span>
        <span class="c"># Remove &#39;self&#39;</span>
        <span class="n">rescale_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">args</span> <span class="o">+=</span> <span class="n">rescale_args</span>
        <span class="n">args</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">args</span>
</div>
<div class="viewcode-block" id="RescaledRegressionMixin.rescale_init"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRegressionMixin.rescale_init">[docs]</a>    <span class="k">def</span> <span class="nf">rescale_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">constrain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constrain</span> <span class="o">=</span> <span class="n">constrain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span> <span class="o">=</span> <span class="n">rescale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_min</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_max</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">yhat_mean</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">yhat_sd</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_mean</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_sd</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="nb">super</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

</div></div>
<div class="viewcode-block" id="RescaledRidge"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRidge">[docs]</a><span class="k">class</span> <span class="nc">RescaledRidge</span><span class="p">(</span><span class="n">Ridge</span><span class="p">,</span> <span class="n">RescaledRegressionMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">constrain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_init</span><span class="p">(</span><span class="n">constrain</span><span class="o">=</span><span class="n">constrain</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="n">rescale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_get_param_names</span><span class="p">()</span>

<div class="viewcode-block" id="RescaledRidge.fit"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRidge.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="RescaledRidge.predict"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledRidge.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

</div></div>
<div class="viewcode-block" id="RescaledSVR"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledSVR">[docs]</a><span class="k">class</span> <span class="nc">RescaledSVR</span><span class="p">(</span><span class="n">SVR</span><span class="p">,</span> <span class="n">RescaledRegressionMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">constrain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_init</span><span class="p">(</span><span class="n">constrain</span><span class="o">=</span><span class="n">constrain</span><span class="p">,</span> <span class="n">rescale</span><span class="o">=</span><span class="n">rescale</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_get_param_names</span><span class="p">()</span>

<div class="viewcode-block" id="RescaledSVR.fit"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledSVR.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="RescaledSVR.predict"><a class="viewcode-back" href="../../skll.html#skll.learner.RescaledSVR.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

</div></div>
<div class="viewcode-block" id="Learner"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner">[docs]</a><span class="k">class</span> <span class="nc">Learner</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A simpler learner interface around many scikit-learn classification</span>
<span class="sd">    and regression functions.</span>

<span class="sd">    :param do_scale_features: Should we scale features with this</span>
<span class="sd">                              learner?</span>
<span class="sd">    :type do_scale_features: bool</span>
<span class="sd">    :param model_type: Type of estimator to create. Options are:</span>
<span class="sd">                       &#39;logistic&#39;, &#39;svm_linear&#39;, &#39;svm_radial&#39;,</span>
<span class="sd">                       &#39;naivebayes&#39;, &#39;dtree&#39;, &#39;rforest&#39;, and &#39;gradient&#39;</span>
<span class="sd">    :type model_type: basestring</span>
<span class="sd">    :param probability: Should learner return probabilities of all</span>
<span class="sd">                        classes (instead of just class with highest</span>
<span class="sd">                        probability)?</span>
<span class="sd">    :type probability: bool</span>
<span class="sd">    :param model_kwargs: A dictionary of keyword arguments to pass to the</span>
<span class="sd">                         initializer for the specified model.</span>
<span class="sd">    :type model_kwargs: dict</span>
<span class="sd">    :param pos_label_str: The string for the positive class in the binary</span>
<span class="sd">                          classification setting.  Otherwise, an arbitrary</span>
<span class="sd">                          class is picked.</span>
<span class="sd">    :type pos_label_str: str</span>
<span class="sd">    :param use_dense_features: Whether to require conversion to dense</span>
<span class="sd">                               feature matrices.</span>
<span class="sd">    :type use_dense_features: bool</span>
<span class="sd">    :param min_feature_count: The minimum number of examples a feature</span>
<span class="sd">                              must have a nonzero value in to be included.</span>
<span class="sd">    :type min_feature_count: int</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">do_scale_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">model_type</span><span class="o">=</span><span class="s">&#39;logistic&#39;</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pos_label_str</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">use_dense_features</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">min_feature_count</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initializes a learner object with the specified settings.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Learner</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probability</span> <span class="o">=</span> <span class="n">probability</span> <span class="k">if</span> <span class="n">model_type</span> <span class="o">!=</span> <span class="s">&#39;svm_linear&#39;</span> <span class="k">else</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_scale_features</span> <span class="o">=</span> <span class="n">do_scale_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_label_str</span> <span class="o">=</span> <span class="n">pos_label_str</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">=</span> <span class="n">model_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_dense_features</span> <span class="o">=</span> <span class="n">use_dense_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_min_feature_count</span> <span class="o">=</span> <span class="n">min_feature_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_use_dense_features</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REQUIRES_DENSE</span> <span class="ow">or</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">_use_dense_features</span><span class="p">)</span>

        <span class="c"># Set default keyword arguments for models that we have some for.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;svm_radial&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;cache_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;probability&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;dtree&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;criterion&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&#39;entropy&#39;</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;rforest&#39;</span><span class="p">,</span> <span class="s">&#39;gradient&#39;</span><span class="p">,</span> <span class="s">&#39;gb_regressor&#39;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;n_estimators&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">500</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;rforest&#39;</span><span class="p">,</span> <span class="s">&#39;dtree&#39;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;compute_importances&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;rforest&#39;</span><span class="p">,</span> <span class="s">&#39;svm_linear&#39;</span><span class="p">,</span> <span class="s">&#39;logistic&#39;</span><span class="p">,</span> <span class="s">&#39;dtree&#39;</span><span class="p">,</span>
                                <span class="s">&#39;gradient&#39;</span><span class="p">,</span> <span class="s">&#39;gb_regressor&#39;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">[</span><span class="s">&#39;random_state&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">123456789</span>

        <span class="k">if</span> <span class="n">model_kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">model_kwargs</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
<div class="viewcode-block" id="Learner.from_file"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.from_file">[docs]</a>    <span class="k">def</span> <span class="nf">from_file</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">learner_path</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :returns: A new instance of Learner from the pickle at the specified</span>
<span class="sd">        path.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">learner_file</span><span class="p">,</span> <span class="s">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</div>
    <span class="nd">@property</span>
<div class="viewcode-block" id="Learner.model_type"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.model_type">[docs]</a>    <span class="k">def</span> <span class="nf">model_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; A string representation of the underlying modeltype &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span>
</div>
    <span class="nd">@property</span>
<div class="viewcode-block" id="Learner.model_kwargs"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.model_kwargs">[docs]</a>    <span class="k">def</span> <span class="nf">model_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        A dictionary of the underlying scikit-learn model&#39;s keyword arguments</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span>
</div>
    <span class="nd">@property</span>
<div class="viewcode-block" id="Learner.model"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.model">[docs]</a>    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; The underlying scikit-learn model &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</div>
<div class="viewcode-block" id="Learner.load"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learner_path</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Replace the current learner instance with a saved learner.</span>

<span class="sd">        :param learner_path: The path to the file to load.</span>
<span class="sd">        :type learner_path: basestring</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span> <span class="o">=</span> <span class="n">Learner</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">learner_path</span><span class="p">)</span><span class="o">.</span><span class="n">__dict__</span>
</div>
    <span class="nd">@property</span>
<div class="viewcode-block" id="Learner.model_params"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.model_params">[docs]</a>    <span class="k">def</span> <span class="nf">model_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Model parameters (i.e., weights) for ridge regression and</span>
<span class="sd">        liblinear models.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">):</span>
            <span class="c"># also includes RescaledRidge</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">iteritems</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">coef</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                    <span class="n">res</span><span class="p">[</span><span class="n">feat</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="n">BaseLibLinear</span><span class="p">):</span>

            <span class="n">label_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span>

            <span class="c"># if there are only two classes, scikit-learn will only have one set</span>
            <span class="c"># of parameters and they will be associated with label 1 (not 0)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">label_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">label_list</span><span class="p">):</span>
                <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">feat</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">coef</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                        <span class="n">res</span><span class="p">[</span><span class="s">&#39;{}</span><span class="se">\t</span><span class="s">{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">feat</span><span class="p">)]</span> <span class="o">=</span> <span class="n">coef</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># not supported</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s">&quot;{} is not supported by&quot;</span> <span class="o">+</span>
                              <span class="s">&quot; model_params.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">res</span>
</div>
<div class="viewcode-block" id="Learner.save"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learner_path</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Save the learner to a file.</span>

<span class="sd">        :param learner_path: The path to where you want to save the learner.</span>
<span class="sd">        :type learner_path: basestring</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># create the directory if it doesn&#39;t exist</span>
        <span class="n">learner_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">learner_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">learner_dir</span><span class="p">):</span>
            <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="s">&quot;mkdir -p {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">learner_dir</span><span class="p">),</span> <span class="n">shell</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c"># write out the files</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">learner_path</span><span class="p">,</span> <span class="s">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</div>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_extract_features</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :returns: A dictionary of feature values extracted from a preprocessed</span>
<span class="sd">        example.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">example</span><span class="p">[</span><span class="s">&quot;x&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_extract_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :returns: The label for a preprocessed example.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s">&quot;y&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s">&quot;y&quot;</span><span class="p">]]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_extract_id</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :returns: The string ID for a preprocessed example.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">example</span><span class="p">[</span><span class="s">&quot;id&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_create_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        :returns: A tuple containing an instantiation of the requested</span>
<span class="sd">        estimator, and a parameter grid to search.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">default_param_grid</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;logistic&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;svm_linear&#39;</span><span class="p">:</span>  <span class="c"># No predict_proba support</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;svm_radial&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;naivebayes&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;dtree&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s">&quot;auto&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;rforest&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="bp">None</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&quot;gradient&quot;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                                   <span class="s">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;ridge&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;rescaled_ridge&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">RescaledRidge</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;svr_linear&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">b</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;rescaled_svr_linear&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">RescaledSVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">b</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]}]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">==</span> <span class="s">&#39;gb_regressor&#39;</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_kwargs</span><span class="p">)</span>
            <span class="n">default_param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
                                   <span class="s">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]}]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s">&quot;{} is not a valid learner &quot;</span> <span class="o">+</span>
                              <span class="s">&quot;type.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">default_param_grid</span>

    <span class="k">def</span> <span class="nf">_check_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        check that the examples are properly formatted.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c"># Make sure the labels for a regression task are not strings.</span>
        <span class="c"># Note: this is redundant because of how _extract_label is used</span>
        <span class="c"># in train setup, but it&#39;s probably useful to leave it in</span>
        <span class="c"># just in case.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_label</span><span class="p">(</span><span class="n">ex</span><span class="p">),</span> <span class="n">string_types</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s">&quot;You are doing regression with&quot;</span> <span class="o">+</span>
                                    <span class="s">&quot; string labels.  Convert them to&quot;</span> <span class="o">+</span>
                                    <span class="s">&quot; integers or floats.&quot;</span><span class="p">)</span>

        <span class="c">#min_feat_abs = float(&quot;inf&quot;)</span>
        <span class="n">max_feat_abs</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&quot;-inf&quot;</span><span class="p">)</span>

        <span class="c"># make sure that feature values are not strings</span>
        <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">ex</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="c">#min_feat_abs = min(min_feat_abs, abs(val)) if val</span>
                <span class="c">#                                           else min_feat_abs</span>
                <span class="n">max_feat_abs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_feat_abs</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">string_types</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s">&quot;You have feature values that are&quot;</span> <span class="o">+</span>
                                    <span class="s">&quot; strings.  Convert them to floats.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_feat_abs</span> <span class="o">&gt;</span> <span class="mf">1000.0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">((</span><span class="s">&quot;You have a feature with a very large absolute value ({}).&quot;</span> <span class="o">+</span>
                   <span class="s">&quot; That may cause the learning algorithm to crash or&quot;</span> <span class="o">+</span>
                   <span class="s">&quot; perform poorly.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_feat_abs</span><span class="p">),</span>
                  <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set up the feature vectorizer, the scaler and the label dict and</span>
<span class="sd">        return the features and the labels.</span>

<span class="sd">        :param examples: The examples to use for training.</span>
<span class="sd">        :type examples: array</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c"># extract the features and the labels</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_input</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

        <span class="c"># Create label_dict if we weren&#39;t passed one</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>

            <span class="c"># extract list of unique labels if we are doing classification</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">([</span><span class="n">example</span><span class="p">[</span><span class="s">&quot;y&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span>
                                         <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

            <span class="c"># if one label is specified as the positive class, make sure it&#39;s</span>
            <span class="c"># last</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_label_str</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">,</span>
                                         <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_label_str</span><span class="p">,</span>
                                                        <span class="n">x</span><span class="p">))</span>

            <span class="c"># Given a list of all labels in the dataset and a list of the</span>
            <span class="c"># unique labels in the set, convert the first list to an array of</span>
            <span class="c"># numbers.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_label</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span>

        <span class="c"># Create feature name -&gt; value mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_dense_features</span><span class="p">)</span>

        <span class="c"># initialize feature selector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span> <span class="o">=</span> <span class="n">SelectByMinCount</span><span class="p">(</span><span class="n">min_count</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_min_feature_count</span><span class="p">)</span>

        <span class="c"># Create scaler if we weren&#39;t passed one</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;naivebayes&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_scale_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">FixedStandardScaler</span><span class="p">(</span><span class="n">copy</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                                  <span class="n">with_mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_dense_features</span><span class="p">,</span>
                                                  <span class="n">with_std</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c"># Doing this is to prevent any modification of feature values</span>
                <span class="c"># using a dummy transformation</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">FixedStandardScaler</span><span class="p">(</span><span class="n">copy</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                                  <span class="n">with_mean</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                                  <span class="n">with_std</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">y</span>

<div class="viewcode-block" id="Learner.train"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">grid_search_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
              <span class="n">grid_search</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">grid_objective</span><span class="o">=</span><span class="n">f1_score_micro</span><span class="p">,</span> <span class="n">grid_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
              <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Train a classification model and return the model, score, feature</span>
<span class="sd">        vectorizer, scaler, label dictionary, and inverse label dictionary.</span>

<span class="sd">        :param examples: The examples to train the model on.</span>
<span class="sd">        :type examples: array</span>
<span class="sd">        :param param_grid: The parameter grid to search through for grid</span>
<span class="sd">                           search. If unspecified, a default parameter grid</span>
<span class="sd">                           will be used.</span>
<span class="sd">        :type param_grid: list of dicts mapping from basestrings to</span>
<span class="sd">                          lists of parameter values</span>
<span class="sd">        :param grid_search_folds: The number of folds to use when doing the</span>
<span class="sd">                                  grid search, or a mapping from</span>
<span class="sd">                                  example IDs to folds.</span>
<span class="sd">        :type grid_search_folds: int or dict</span>
<span class="sd">        :param grid_search: Should we do grid search?</span>
<span class="sd">        :type grid_search: bool</span>
<span class="sd">        :param grid_objective: The objective function to use when doing the</span>
<span class="sd">                               grid search.</span>
<span class="sd">        :type grid_objective: function</span>
<span class="sd">        :param grid_jobs: The number of jobs to run in parallel when doing the</span>
<span class="sd">                          grid search. If unspecified or None, the number of</span>
<span class="sd">                          grid search folds will be used.</span>
<span class="sd">        :type grid_jobs: int</span>
<span class="sd">        :param shuffle: Shuffle examples (e.g., for grid search CV.)</span>
<span class="sd">        :type shuffle: bool</span>

<span class="sd">        :return: The best grid search objective function score, or 0 if we&#39;re</span>
<span class="sd">                 not doing grid search.</span>
<span class="sd">        :rtype: float</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c"># seed the random number generator so that randomized algorithms are</span>
        <span class="c"># replicable</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">9876315986142</span><span class="p">)</span>

        <span class="c"># shuffle so that the folds are random for the inner grid search CV</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

        <span class="c"># call train setup to set up the vectorizer, the labeldict, and the</span>
        <span class="c"># scaler</span>
        <span class="n">features</span><span class="p">,</span> <span class="n">ytrain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_setup</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

        <span class="c"># set up grid search folds</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grid_search_folds</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">grid_jobs</span> <span class="o">=</span> <span class="n">grid_search_folds</span>
            <span class="n">folds</span> <span class="o">=</span> <span class="n">grid_search_folds</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># use the number of unique fold IDs as the number of grid jobs</span>
            <span class="n">grid_jobs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">grid_search_folds</span><span class="p">))</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">grid_search_folds</span><span class="p">[</span><span class="n">ex</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
            <span class="n">folds</span> <span class="o">=</span> <span class="n">LeaveOneLabelOut</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="c"># vectorize the features</span>
        <span class="n">xtrain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c"># select features</span>
        <span class="n">xtrain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

        <span class="c"># Scale features if necessary</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;naivebayes&#39;</span><span class="p">:</span>
            <span class="n">xtrain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

        <span class="c"># set up a grid searcher if we are asked to</span>
        <span class="n">estimator</span><span class="p">,</span> <span class="n">default_param_grid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_estimator</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">grid_search</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">param_grid</span><span class="p">:</span>
                <span class="n">param_grid</span> <span class="o">=</span> <span class="n">default_param_grid</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">grid_objective</span><span class="o">.</span><span class="n">__name__</span> <span class="ow">in</span> <span class="n">_CORRELATION_METRICS</span> <span class="ow">and</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict_normal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict</span> <span class="o">=</span> <span class="n">_predict_binary</span>

            <span class="n">grid_searcher</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span>
                                         <span class="n">score_func</span><span class="o">=</span><span class="n">grid_objective</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span>
                                         <span class="n">n_jobs</span><span class="o">=</span><span class="n">grid_jobs</span><span class="p">)</span>

            <span class="c"># run the grid search for hyperparameters</span>
            <span class="n">grid_searcher</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">grid_searcher</span><span class="o">.</span><span class="n">best_estimator_</span>
            <span class="n">grid_score</span> <span class="o">=</span> <span class="n">grid_searcher</span><span class="o">.</span><span class="n">best_score_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
            <span class="n">grid_score</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">grid_score</span>
</div>
<div class="viewcode-block" id="Learner.evaluate"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.evaluate">[docs]</a>    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">prediction_prefix</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">grid_objective</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Evaluates a given model on a given dev or test example set.</span>

<span class="sd">        :param examples: The examples to evaluate the performance of the model</span>
<span class="sd">            on.</span>
<span class="sd">        :type examples: array</span>
<span class="sd">        :param prediction_prefix: If saving the predictions, this is the</span>
<span class="sd">                                  prefix that will be used for the filename.</span>
<span class="sd">                                  It will be followed by &quot;.predictions&quot;</span>
<span class="sd">        :type prediction_prefix: basestring</span>
<span class="sd">        :param append: Should we append the current predictions to the file if</span>
<span class="sd">                       it exists?</span>
<span class="sd">        :type append: bool</span>
<span class="sd">        :param grid_objective: The objective function that was used when doing</span>
<span class="sd">                               the grid search.</span>
<span class="sd">        :type grid_objective: function</span>

<span class="sd">        :return: The confusion matrix, the overall accuracy, the per-class</span>
<span class="sd">                 PRFs, the model parameters, and the grid search objective</span>
<span class="sd">                 function score.</span>
<span class="sd">        :rtype: 3-tuple</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># initialize grid score</span>
        <span class="n">grid_score</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="c"># make the prediction on the test data</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">prediction_prefix</span><span class="o">=</span><span class="n">prediction_prefix</span><span class="p">,</span>
                            <span class="n">append</span><span class="o">=</span><span class="n">append</span><span class="p">)</span>

        <span class="c"># extract actual labels</span>
        <span class="n">ytest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_label</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span>

        <span class="c"># if run in probability mode, convert yhat to list of classes predicted</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability</span><span class="p">:</span>
            <span class="c"># if we&#39;re using a correlation grid objective, calculate it here</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">grid_objective</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span>
                    <span class="n">grid_objective</span><span class="o">.</span><span class="n">__name__</span> <span class="ow">in</span> <span class="n">_CORRELATION_METRICS</span><span class="p">):</span>
                <span class="n">grid_score</span> <span class="o">=</span> <span class="n">grid_objective</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">yhat</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">row</span><span class="p">)),</span>
                                 <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                             <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">yhat</span><span class="p">])</span>

        <span class="c"># calculate grid search objective function score, if specified</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">grid_objective</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span>
                <span class="p">(</span><span class="n">grid_objective</span><span class="o">.</span><span class="n">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_CORRELATION_METRICS</span> <span class="ow">or</span>
                 <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability</span><span class="p">)):</span>
            <span class="n">grid_score</span> <span class="o">=</span> <span class="n">grid_objective</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">get_params</span><span class="p">(),</span> <span class="n">grid_score</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># compute the confusion matrix</span>
            <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">)</span>
            <span class="n">conf_mat</span> <span class="o">=</span> <span class="n">sk_metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span>
                                                   <span class="n">labels</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_labels</span><span class="p">)))</span>
            <span class="c"># Calculate metrics</span>
            <span class="n">overall_accuracy</span> <span class="o">=</span> <span class="n">sk_metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
            <span class="n">result_matrix</span> <span class="o">=</span> <span class="n">sk_metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span>
                                                                       <span class="n">yhat</span><span class="p">,</span>
                                                                       <span class="n">labels</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_labels</span><span class="p">)),</span>
                                                                       <span class="n">average</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

            <span class="c"># Store results</span>
            <span class="n">result_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">actual_class</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">):</span>
                <span class="n">c_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="p">[</span><span class="n">actual_class</span><span class="p">]</span>
                <span class="n">result_dict</span><span class="p">[</span><span class="n">actual_class</span><span class="p">][</span><span class="s">&quot;Precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">c_num</span><span class="p">]</span>
                <span class="n">result_dict</span><span class="p">[</span><span class="n">actual_class</span><span class="p">][</span><span class="s">&quot;Recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">c_num</span><span class="p">]</span>
                <span class="n">result_dict</span><span class="p">[</span><span class="n">actual_class</span><span class="p">][</span><span class="s">&quot;F-measure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result_matrix</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">c_num</span><span class="p">]</span>

            <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">conf_mat</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">overall_accuracy</span><span class="p">,</span> <span class="n">result_dict</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">get_params</span><span class="p">(),</span> <span class="n">grid_score</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>
</div>
<div class="viewcode-block" id="Learner.predict"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">prediction_prefix</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                <span class="n">class_labels</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Uses a given model to generate predictions on a given data set</span>

<span class="sd">        :param examples: The examples to predict the classes for.</span>
<span class="sd">        :type examples: array</span>
<span class="sd">        :param prediction_prefix: If saving the predictions, this is the</span>
<span class="sd">                                  prefix that will be used for the</span>
<span class="sd">                                  filename. It will be followed by</span>
<span class="sd">                                  &quot;.predictions&quot;</span>
<span class="sd">        :type prediction_prefix: basestring</span>
<span class="sd">        :param append: Should we append the current predictions to the file if</span>
<span class="sd">                       it exists?</span>
<span class="sd">        :type append: bool</span>
<span class="sd">        :param class_labels: For classifier, should we convert class</span>
<span class="sd">                             indices to their (str) labels?</span>
<span class="sd">        :type class_labels: bool</span>

<span class="sd">        :return: The predictions returned by the learner.</span>
<span class="sd">        :rtype: array</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
        <span class="n">example_ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_id</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>

        <span class="c"># transform the features</span>
        <span class="n">xtest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c"># filter features based on those selected from training set</span>
        <span class="n">xtest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>

        <span class="c"># Scale xtest</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;naivebayes&#39;</span><span class="p">:</span>
            <span class="n">xtest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>

        <span class="c"># make the prediction on the test data</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probability</span> <span class="ow">and</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;svm_linear&#39;</span> <span class="ow">and</span>
                        <span class="ow">not</span> <span class="n">class_labels</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">NotImplementedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">print</span><span class="p">((</span><span class="s">&quot;Model type: {}</span><span class="se">\n</span><span class="s">Model: {}</span><span class="se">\n</span><span class="s">Probability: &quot;</span> <span class="o">+</span>
                   <span class="s">&quot;{}</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">probability</span><span class="p">),</span>
                  <span class="nb">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">e</span>

        <span class="c"># write out the predictions if we are asked to</span>
        <span class="k">if</span> <span class="n">prediction_prefix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">prediction_file</span> <span class="o">=</span> <span class="s">&#39;{}.predictions&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prediction_prefix</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">prediction_file</span><span class="p">,</span>
                      <span class="s">&quot;w&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">append</span> <span class="k">else</span> <span class="s">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">predictionfh</span><span class="p">:</span>
                <span class="c"># header</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">append</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;svm_linear&#39;</span><span class="p">:</span>
                        <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s">&quot;id&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">),</span>
                              <span class="nb">file</span><span class="o">=</span><span class="n">predictionfh</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s">&quot;id&quot;</span><span class="p">,</span> <span class="s">&quot;prediction&quot;</span><span class="p">]),</span>
                              <span class="nb">file</span><span class="o">=</span><span class="n">predictionfh</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">probability</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="o">!=</span> <span class="s">&#39;svm_linear&#39;</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">example_id</span><span class="p">,</span> <span class="n">class_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">example_ids</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
                        <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">example_id</span><span class="p">]</span> <span class="o">+</span>
                                        <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">class_probs</span><span class="p">]),</span>
                              <span class="nb">file</span><span class="o">=</span><span class="n">predictionfh</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">example_id</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">example_ids</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
                            <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">example_id</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred</span><span class="p">)]),</span>
                                  <span class="nb">file</span><span class="o">=</span><span class="n">predictionfh</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">example_id</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">example_ids</span><span class="p">,</span> <span class="n">yhat</span><span class="p">):</span>
                            <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">example_id</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">)]]),</span>
                                  <span class="nb">file</span><span class="o">=</span><span class="n">predictionfh</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">class_labels</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">:</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">label_list</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">)]</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">yhat</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">yhat</span>
</div>
<div class="viewcode-block" id="Learner.cross_validate"><a class="viewcode-back" href="../../skll.html#skll.learner.Learner.cross_validate">[docs]</a>    <span class="k">def</span> <span class="nf">cross_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cv_folds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                       <span class="n">grid_search</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">grid_search_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">grid_jobs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                       <span class="n">grid_objective</span><span class="o">=</span><span class="n">f1_score_micro</span><span class="p">,</span> <span class="n">prediction_prefix</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                       <span class="n">param_grid</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Cross-validates a given model on the training examples.</span>

<span class="sd">        :param examples: The data to cross-validate learner performance on.</span>
<span class="sd">        :type examples: array</span>
<span class="sd">        :param stratified: Should we stratify the folds to ensure an even</span>
<span class="sd">                           distribution of classes for each fold?</span>
<span class="sd">        :type stratified: bool</span>
<span class="sd">        :param cv_folds: The number of folds to use for cross-validation, or</span>
<span class="sd">                         a mapping from example IDs to folds.</span>
<span class="sd">        :type cv_folds: int or dict</span>
<span class="sd">        :param grid_search: Should we do grid search when training each fold?</span>
<span class="sd">                            Note: This will make this take *much* longer.</span>
<span class="sd">        :type grid_search: bool</span>
<span class="sd">        :param grid_search_folds: The number of folds to use when doing the</span>
<span class="sd">                                  grid search (ignored if cv_folds is set to</span>
<span class="sd">                                  a dictionary mapping examples to folds).</span>
<span class="sd">        :type grid_search_folds: int</span>
<span class="sd">        :param grid_jobs: The number of jobs to run in parallel when doing the</span>
<span class="sd">                          grid search. If unspecified or None, the number of</span>
<span class="sd">                          grid search folds will be used.</span>
<span class="sd">        :type grid_jobs: int</span>
<span class="sd">        :param grid_objective: The objective function to use when doing the</span>
<span class="sd">                               grid search.</span>
<span class="sd">        :type grid_objective: function</span>
<span class="sd">        :param param_grid: The parameter grid to search through for grid</span>
<span class="sd">                           search. If unspecified, a default parameter</span>
<span class="sd">                           grid will be used.</span>
<span class="sd">        :type param_grid: list of dicts mapping from basestrings to</span>
<span class="sd">                          lists of parameter values</span>
<span class="sd">        :param prediction_prefix: If saving the predictions, this is the</span>
<span class="sd">                                  prefix that will be used for the filename.</span>
<span class="sd">                                  It will be followed by &quot;.predictions&quot;</span>
<span class="sd">        :type prediction_prefix: basestring</span>
<span class="sd">        :param shuffle: Shuffle examples before splitting into folds for CV.</span>
<span class="sd">        :type shuffle: bool</span>

<span class="sd">        :return: The confusion matrix, overall accuracy, per-class PRFs, and</span>
<span class="sd">                 model parameters for each fold.</span>
<span class="sd">        :rtype: list of 4-tuples</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c"># seed the random number generator so that randomized folds are</span>
        <span class="c"># replicable</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">9876315986142</span><span class="p">)</span>

        <span class="c"># Shuffle examples before splitting</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

        <span class="c"># call train setup</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_setup</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

        <span class="c"># setup the cross-validation iterator</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv_folds</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">stratified</span> <span class="o">=</span> <span class="p">(</span><span class="n">stratified</span> <span class="ow">and</span>
                          <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_type</span> <span class="ow">in</span> <span class="n">_REGRESSION_MODELS</span><span class="p">)</span>
            <span class="n">kfold</span> <span class="o">=</span> <span class="p">(</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">)</span> <span class="k">if</span> <span class="n">stratified</span>
                     <span class="k">else</span> <span class="n">KFold</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">),</span> <span class="n">n_folds</span><span class="o">=</span><span class="n">cv_folds</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># if we have a mapping from IDs to folds, use it for the overall</span>
            <span class="c"># cross-validation as well as the grid search within each</span>
            <span class="c"># training fold.  Note that this means that the grid search</span>
            <span class="c"># will use K-1 folds because the Kth will be the test fold for</span>
            <span class="c"># the outer cross-validation.</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv_folds</span><span class="p">[</span><span class="n">ex</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
            <span class="n">kfold</span> <span class="o">=</span> <span class="n">LeaveOneLabelOut</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">grid_search_folds</span> <span class="o">=</span> <span class="n">cv_folds</span>

        <span class="c"># handle each fold separately and accumulate the predictions and the</span>
        <span class="c"># numbers</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">grid_search_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">append_predictions</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kfold</span><span class="p">:</span>
            <span class="c"># Train model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c"># prevent feature vectorizer from being reset.</span>
            <span class="n">grid_search_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span>
                                                 <span class="n">grid_search_folds</span><span class="o">=</span><span class="n">grid_search_folds</span><span class="p">,</span>
                                                 <span class="n">grid_search</span><span class="o">=</span><span class="n">grid_search</span><span class="p">,</span>
                                                 <span class="n">grid_objective</span><span class="o">=</span><span class="n">grid_objective</span><span class="p">,</span>
                                                 <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
                                                 <span class="n">grid_jobs</span><span class="o">=</span><span class="n">grid_jobs</span><span class="p">,</span>
                                                 <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
            <span class="c"># note: there is no need to shuffle again within each fold,</span>
            <span class="c"># regardless of what the shuffle keyword argument is set to.</span>

            <span class="c"># Evaluate model</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">test_index</span><span class="p">],</span>
                                         <span class="n">prediction_prefix</span><span class="o">=</span><span class="n">prediction_prefix</span><span class="p">,</span>
                                         <span class="n">append</span><span class="o">=</span><span class="n">append_predictions</span><span class="p">,</span>
                                         <span class="n">grid_objective</span><span class="o">=</span><span class="n">grid_objective</span><span class="p">))</span>

            <span class="n">append_predictions</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="c"># return list of results for all folds</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">,</span> <span class="n">grid_search_scores</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">SciKit-Learn Lab 0.9 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012-2013, Educational Testing Service.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b1.
    </div>
  </body>
</html>